{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-DigitalAcademy/TrendHunt-Application/blob/Model/Model_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEjvKf5DglU8",
        "outputId": "1e4ea05c-a397-409f-d841-e1adb6aba902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyJieh1yM7xj",
        "outputId": "48e0ff8c-7296-4be0-b707-3c9a140ac378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from scipy.spatial import distance\n",
        "import pandas as pd\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "model = VGG16(weights='imagenet')\n",
        "\n",
        "# Load the saved PCA features and images list\n",
        "file_path = '/content/my_data.p'\n",
        "images, pca_features, pca = pickle.load(open(file_path, 'rb'))\n",
        "\n",
        "# Define the feature extractor using the VGG16 model\n",
        "base_model = VGG16(weights='imagenet')\n",
        "layer_name = 'fc2'\n",
        "feat_extractor = keras.models.Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_image(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "\n",
        "    # Ensure the image is in RGB mode\n",
        "    if img.mode != \"RGB\":\n",
        "        img = img.convert(\"RGB\")\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Trendhunt Application\")\n",
        "\n",
        "# Landing page (About and Login)\n",
        "landing_page = st.sidebar.selectbox(\"Select Page\", [\"About\", \"Login\"])\n",
        "\n",
        "if landing_page == \"About\":\n",
        "    st.write(\"The Trendhunt app is a revolutionary solution designed to address the challenges people face in locating specific items they desire in today's digital age. With the abundance of information on the internet, finding the exact product can be a daunting task. Trendhunt aims to simplify this process by providing a comprehensive and easily accessible platform for users to discover similar items based on a picture they upload.\")\n",
        "\n",
        "    # Add a picture under the \"Trendhunt application\" text\n",
        "    st.sidebar.image(\"https://i.fbcd.co/products/resized/resized-750-500/ddc5250f28dcf85d8238ecc732a8752b73e3685762d6dad4b32c4c9359538e77.jpg\", caption=\"Trendhunt Logo\", use_column_width=True)\n",
        "\n",
        "elif landing_page == \"Login\":\n",
        "    st.sidebar.write(\"Login Page\")\n",
        "    username = st.text_input(\"Username\")\n",
        "    password = st.text_input(\"Password\", type=\"password\")\n",
        "    login_button = st.button(\"Login\")\n",
        "\n",
        "    if login_button:\n",
        "        # Check login credentials (you can replace this with your authentication logic)\n",
        "        if username == \"your_username\" and password == \"your_password\":\n",
        "            st.success(\"Login successful! Redirecting to the upload page...\")\n",
        "            landing_page = \"Upload Image\"  # Redirect to the upload page\n",
        "        else:\n",
        "            st.error(\"Login failed. Please check your credentials.\")\n",
        "\n",
        "# Upload an image\n",
        "uploaded_image = st.file_uploader(\"Upload an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_image is not None:\n",
        "    # Display the uploaded image\n",
        "    st.image(uploaded_image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Perform predictions on the uploaded image\n",
        "    img = Image.open(uploaded_image)\n",
        "\n",
        "    # Convert the image to RGB mode explicitly\n",
        "    img = img.convert(\"RGB\")\n",
        "\n",
        "    img_path = \"temp_image.jpg\"\n",
        "    img.save(img_path)\n",
        "\n",
        "    # Load and preprocess the uploaded image\n",
        "    x = load_image(img_path)\n",
        "\n",
        "    # Make predictions using the model\n",
        "    predictions = model.predict(x)\n",
        "\n",
        "    # Decode the predictions to get class labels and probabilities\n",
        "    decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
        "\n",
        "\n",
        "    # Calculate PCA features for the uploaded image\n",
        "    img_features = feat_extractor.predict(x)[0]\n",
        "    img_pca_features = pca.transform([img_features])[0]\n",
        "\n",
        "    # Calculate distances to all other images\n",
        "    distances = [distance.cosine(img_pca_features, feat) for feat in pca_features]\n",
        "    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[0:5]\n",
        "\n",
        "    st.subheader(\"Most Similar Images:\")\n",
        "\n",
        "    # Read the data from the CSV file once\n",
        "    data = pd.read_csv(\"styles.csv\", encoding='utf-8', error_bad_lines=False, warn_bad_lines=True)\n",
        "\n",
        "    for idx in idx_closest:\n",
        "        similar_img = Image.open(images[idx])\n",
        "        product_id = os.path.splitext(os.path.basename(images[idx]))[0]\n",
        "        caption = data[data['id'] == int(product_id)]['productDisplayName'].values[0]\n",
        "        caption1 = data[data['id'] == int(product_id)]['gender'].values[0]\n",
        "\n",
        "        st.image(similar_img, use_column_width=True)\n",
        "        lst = [caption, caption1]\n",
        "\n",
        "        lst = [f'Product Name: {caption}' , f'Gender: {caption1}']\n",
        "        for i in lst:\n",
        "            st.markdown(i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlAx1hF_gjJW",
        "outputId": "2c567b28-6344-4da8-867c-c96a3e33eaa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.225.105.137\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBUtL86BhGt3",
        "outputId": "a42f570f-64c0-4c65-fcc9-fb6021651ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[#.................] - fetchMetadata: sill resolveWithNewModule follow-redirect\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.225.105.137:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.932s\n",
            "your url is: https://whole-pugs-deny.loca.lt\n",
            "2023-09-20 14:25:32.149263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-20 14:25:33.927769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "1/1 [==============================] - 1s 845ms/step\n",
            "1/1 [==============================] - 1s 823ms/step\n",
            "/content/app.py:101: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  data = pd.read_csv(\"styles.csv\", encoding='utf-8', error_bad_lines=False, warn_bad_lines=True)\n",
            "/content/app.py:101: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  data = pd.read_csv(\"styles.csv\", encoding='utf-8', error_bad_lines=False, warn_bad_lines=True)\n",
            "Skipping line 6044: expected 10 fields, saw 11\n",
            "Skipping line 6569: expected 10 fields, saw 11\n",
            "Skipping line 7399: expected 10 fields, saw 11\n",
            "Skipping line 7939: expected 10 fields, saw 11\n",
            "Skipping line 9026: expected 10 fields, saw 11\n",
            "Skipping line 10264: expected 10 fields, saw 11\n",
            "Skipping line 10427: expected 10 fields, saw 11\n",
            "Skipping line 10905: expected 10 fields, saw 11\n",
            "Skipping line 11373: expected 10 fields, saw 11\n",
            "Skipping line 11945: expected 10 fields, saw 11\n",
            "Skipping line 14112: expected 10 fields, saw 11\n",
            "Skipping line 14532: expected 10 fields, saw 11\n",
            "Skipping line 15076: expected 10 fields, saw 12\n",
            "Skipping line 29906: expected 10 fields, saw 11\n",
            "Skipping line 31625: expected 10 fields, saw 11\n",
            "Skipping line 33020: expected 10 fields, saw 11\n",
            "Skipping line 35748: expected 10 fields, saw 11\n",
            "Skipping line 35962: expected 10 fields, saw 11\n",
            "Skipping line 37770: expected 10 fields, saw 11\n",
            "Skipping line 38105: expected 10 fields, saw 11\n",
            "Skipping line 38275: expected 10 fields, saw 11\n",
            "Skipping line 38404: expected 10 fields, saw 12\n",
            "\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UxenI0tWK6k6ueNYYOng7YX2SiLU0nso",
      "authorship_tag": "ABX9TyPO0GZvnozjn+VZ+tnBh97K",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}