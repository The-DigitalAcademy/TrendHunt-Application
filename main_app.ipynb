{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-DigitalAcademy/TrendHunt-Application/blob/Streamlit/main_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEBylCLCgp1n",
        "outputId": "f3cd1cdb-5b05-4120-9095-1902823fa5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxFA6jswglmd",
        "outputId": "a9d45910-4d01-4a84-d88d-27efd3ee8e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.196.210.179\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7eckiqmgeKD",
        "outputId": "114aac9c-b93e-4004-d40b-2b6b3c87b372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from scipy.spatial import distance\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "model = VGG16(weights='imagenet')\n",
        "\n",
        "# Load the saved PCA features and images list\n",
        "file_path = '/content/drive/MyDrive/my data.p'\n",
        "images, pca_features, pca = pickle.load(open(file_path, 'rb'))\n",
        "\n",
        "# Define the feature extractor using the VGG16 model\n",
        "base_model = VGG16(weights='imagenet')\n",
        "layer_name = 'fc2'\n",
        "feat_extractor = keras.models.Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_image(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "\n",
        "    # Ensure the image is in RGB mode\n",
        "    if img.mode != \"RGB\":\n",
        "        img = img.convert(\"RGB\")\n",
        "\n",
        "    x = image.img_to_array(img)\n",
        "    x = preprocess_input(x)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Image Classifier with Streamlit\")\n",
        "\n",
        "# Option to upload an image\n",
        "uploaded_image = st.file_uploader(\"Upload an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "# Option to capture an image using the camera\n",
        "if st.button(\"Capture Image from Camera\"):\n",
        "    st.write(\"Camera Opened\")\n",
        "    camera_image = st.image([], caption=\"Camera Feed\", use_column_width=True, channels=\"BGR\")\n",
        "\n",
        "    # Create a unique filename for the captured image\n",
        "    img_path = \"captured_image.jpg\"\n",
        "\n",
        "    # Capture an image from the camera and save it\n",
        "    camera = cv2.VideoCapture(0)\n",
        "    ret, frame = camera.read()\n",
        "    if ret:\n",
        "        cv2.imwrite(img_path, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        camera_image.image(frame, caption=\"Captured Image\", use_column_width=True)\n",
        "        st.write(\"Image Captured\")\n",
        "    else:\n",
        "        st.write(\"Error capturing image from camera\")\n",
        "    camera.release()\n",
        "\n",
        "if uploaded_image is not None:\n",
        "    # Display the uploaded image\n",
        "    st.image(uploaded_image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Perform predictions on the uploaded image\n",
        "    img = Image.open(uploaded_image)\n",
        "\n",
        "    # Convert the image to RGB mode explicitly\n",
        "    img = img.convert(\"RGB\")\n",
        "\n",
        "    img_path = \"temp_image.jpg\"\n",
        "    img.save(img_path)\n",
        "\n",
        "    # Load and preprocess the uploaded image\n",
        "    x = load_image(img_path)\n",
        "\n",
        "    # Make predictions using the model\n",
        "    predictions = model.predict(x)\n",
        "\n",
        "    # Decode the predictions to get class labels and probabilities\n",
        "    decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
        "\n",
        "    st.subheader(\"Top Predicted Classes:\")\n",
        "    for label, description, score in decoded_predictions:\n",
        "        st.write(f\"{description} ({label}): {score:.2f}\")\n",
        "\n",
        "    # Calculate PCA features for the uploaded image\n",
        "    img_features = feat_extractor.predict(x)[0]\n",
        "    img_pca_features = pca.transform([img_features])[0]\n",
        "\n",
        "    # Calculate distances to all other images\n",
        "    distances = [distance.cosine(img_pca_features, feat) for feat in pca_features]\n",
        "    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[0:5]\n",
        "\n",
        "    st.subheader(\"Most Similar Images:\")\n",
        "    for idx in idx_closest:\n",
        "        similar_img = Image.open(images[idx])\n",
        "        st.image(similar_img, caption=f\"Similar Image {idx}\", use_column_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-ZlQ_lvgw07",
        "outputId": "f24d4749-c567-4db0-9fd3-d625bb09c4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[..................] \\ fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.210.179:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.338s\n",
            "your url is: https://tidy-lines-attack.loca.lt\n",
            "2023-09-19 08:31:09.166449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-19 08:31:11.233189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-09-19 08:31:35.263 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 552, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 46, in <module>\n",
            "    camera_image = st.image([], caption=\"Camera Feed\", use_column_width=True, channels=\"BGR\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/metrics_util.py\", line 358, in wrapped_func\n",
            "    result = non_optional_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 168, in image\n",
            "    marshall_images(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 502, in marshall_images\n",
            "    assert len(captions) == len(images), \"Cannot pair %d captions with %d images.\" % (\n",
            "AssertionError: Cannot pair 1 captions with 0 images.\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16-16TmUC5l1ajMGpu8M1Ll00T-IKIKNc",
      "authorship_tag": "ABX9TyP/OvchWg0PYEC7w9v9gvtk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}